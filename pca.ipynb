{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-13T17:44:53.405106Z",
     "start_time": "2025-10-13T17:44:53.400928Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-13T17:44:54.170096Z",
     "start_time": "2025-10-13T17:44:54.112914Z"
    }
   },
   "cell_type": "code",
   "source": "data = pd.read_csv(\"EKG_pupsniu_analize.csv\", sep=\";\", header=0)",
   "id": "5be6401f1ff1702",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "58895f6f92e0a907"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-13T17:44:57.831439Z",
     "start_time": "2025-10-13T17:44:57.821530Z"
    }
   },
   "cell_type": "code",
   "source": "data.info()\n",
   "id": "d8043d50c334079",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11940 entries, 0 to 11939\n",
      "Data columns (total 32 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   RR_l_0         11940 non-null  float64\n",
      " 1   RR_l_0/RR_l_1  11939 non-null  float64\n",
      " 2   RR_l_1         11939 non-null  float64\n",
      " 3   RR_l_1/RR_l_2  11938 non-null  float64\n",
      " 4   RR_l_2         11938 non-null  float64\n",
      " 5   RR_l_2/RR_l_3  11926 non-null  float64\n",
      " 6   RR_l_3         11936 non-null  float64\n",
      " 7   RR_l_3/RR_l_4  11933 non-null  float64\n",
      " 8   RR_r_0         11932 non-null  object \n",
      " 9   RR_r_0/RR_r_1  11936 non-null  object \n",
      " 10  RR_r_1         11935 non-null  float64\n",
      " 11  RR_r_1/RR_r_2  11932 non-null  float64\n",
      " 12  RR_r_2         11937 non-null  float64\n",
      " 13  RR_r_2/RR_r_3  11935 non-null  float64\n",
      " 14  RR_r_3         11938 non-null  float64\n",
      " 15  RR_r_3/RR_r_4  11938 non-null  float64\n",
      " 16  seq_size       11938 non-null  float64\n",
      " 17  signal_mean    11935 non-null  float64\n",
      " 18  signal_std     11937 non-null  float64\n",
      " 19  wl_side        11939 non-null  float64\n",
      " 20  wr_side        11936 non-null  float64\n",
      " 21  P_val          11938 non-null  float64\n",
      " 22  Q_val          11935 non-null  float64\n",
      " 23  R_val          11935 non-null  float64\n",
      " 24  S_val          11937 non-null  float64\n",
      " 25  T_val          11939 non-null  float64\n",
      " 26  P_pos          11940 non-null  float64\n",
      " 27  Q_pos          11938 non-null  float64\n",
      " 28  R_pos          11940 non-null  float64\n",
      " 29  S_pos          11938 non-null  float64\n",
      " 30  T_pos          11940 non-null  float64\n",
      " 31  label          11923 non-null  float64\n",
      "dtypes: float64(30), object(2)\n",
      "memory usage: 2.9+ MB\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-13T17:41:51.569182Z",
     "start_time": "2025-10-13T17:41:51.520096Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X = data.drop('label', axis=1)\n",
    "y = data['label']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(data)"
   ],
   "id": "cd8054da585c6447",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'a'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mValueError\u001B[39m                                Traceback (most recent call last)",
      "\u001B[32m~\\AppData\\Local\\Temp\\ipykernel_33120\\4052363526.py\u001B[39m in \u001B[36m?\u001B[39m\u001B[34m()\u001B[39m\n\u001B[32m      1\u001B[39m X = data.drop(\u001B[33m'label'\u001B[39m, axis=\u001B[32m1\u001B[39m)\n\u001B[32m      2\u001B[39m y = data[\u001B[33m'label'\u001B[39m]\n\u001B[32m      3\u001B[39m \n\u001B[32m      4\u001B[39m scaler = StandardScaler()\n\u001B[32m----> \u001B[39m\u001B[32m5\u001B[39m X_scaled = scaler.fit_transform(data)\n",
      "\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\u001B[39m in \u001B[36m?\u001B[39m\u001B[34m(self, X, *args, **kwargs)\u001B[39m\n\u001B[32m    314\u001B[39m     @wraps(f)\n\u001B[32m    315\u001B[39m     \u001B[38;5;28;01mdef\u001B[39;00m wrapped(self, X, *args, **kwargs):\n\u001B[32m--> \u001B[39m\u001B[32m316\u001B[39m         data_to_wrap = f(self, X, *args, **kwargs)\n\u001B[32m    317\u001B[39m         \u001B[38;5;28;01mif\u001B[39;00m isinstance(data_to_wrap, tuple):\n\u001B[32m    318\u001B[39m             \u001B[38;5;66;03m# only wrap the first output for cross decomposition\u001B[39;00m\n\u001B[32m    319\u001B[39m             return_tuple = (\n",
      "\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py\u001B[39m in \u001B[36m?\u001B[39m\u001B[34m(self, X, y, **fit_params)\u001B[39m\n\u001B[32m    890\u001B[39m                 )\n\u001B[32m    891\u001B[39m \n\u001B[32m    892\u001B[39m         \u001B[38;5;28;01mif\u001B[39;00m y \u001B[38;5;28;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    893\u001B[39m             \u001B[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m894\u001B[39m             \u001B[38;5;28;01mreturn\u001B[39;00m self.fit(X, **fit_params).transform(X)\n\u001B[32m    895\u001B[39m         \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    896\u001B[39m             \u001B[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001B[39;00m\n\u001B[32m    897\u001B[39m             \u001B[38;5;28;01mreturn\u001B[39;00m self.fit(X, y, **fit_params).transform(X)\n",
      "\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py\u001B[39m in \u001B[36m?\u001B[39m\u001B[34m(self, X, y, sample_weight)\u001B[39m\n\u001B[32m    903\u001B[39m             Fitted scaler.\n\u001B[32m    904\u001B[39m         \"\"\"\n\u001B[32m    905\u001B[39m         \u001B[38;5;66;03m# Reset internal state before fitting\u001B[39;00m\n\u001B[32m    906\u001B[39m         self._reset()\n\u001B[32m--> \u001B[39m\u001B[32m907\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m self.partial_fit(X, y, sample_weight)\n",
      "\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py\u001B[39m in \u001B[36m?\u001B[39m\u001B[34m(estimator, *args, **kwargs)\u001B[39m\n\u001B[32m   1361\u001B[39m                 skip_parameter_validation=(\n\u001B[32m   1362\u001B[39m                     prefer_skip_nested_validation \u001B[38;5;28;01mor\u001B[39;00m global_skip_validation\n\u001B[32m   1363\u001B[39m                 )\n\u001B[32m   1364\u001B[39m             ):\n\u001B[32m-> \u001B[39m\u001B[32m1365\u001B[39m                 \u001B[38;5;28;01mreturn\u001B[39;00m fit_method(estimator, *args, **kwargs)\n",
      "\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py\u001B[39m in \u001B[36m?\u001B[39m\u001B[34m(self, X, y, sample_weight)\u001B[39m\n\u001B[32m    939\u001B[39m         self : object\n\u001B[32m    940\u001B[39m             Fitted scaler.\n\u001B[32m    941\u001B[39m         \"\"\"\n\u001B[32m    942\u001B[39m         first_call = \u001B[38;5;28;01mnot\u001B[39;00m hasattr(self, \u001B[33m\"n_samples_seen_\"\u001B[39m)\n\u001B[32m--> \u001B[39m\u001B[32m943\u001B[39m         X = validate_data(\n\u001B[32m    944\u001B[39m             self,\n\u001B[32m    945\u001B[39m             X,\n\u001B[32m    946\u001B[39m             accept_sparse=(\u001B[33m\"csr\"\u001B[39m, \u001B[33m\"csc\"\u001B[39m),\n",
      "\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py\u001B[39m in \u001B[36m?\u001B[39m\u001B[34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001B[39m\n\u001B[32m   2950\u001B[39m             out = y\n\u001B[32m   2951\u001B[39m         \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m   2952\u001B[39m             out = X, y\n\u001B[32m   2953\u001B[39m     \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28;01mnot\u001B[39;00m no_val_X \u001B[38;5;28;01mand\u001B[39;00m no_val_y:\n\u001B[32m-> \u001B[39m\u001B[32m2954\u001B[39m         out = check_array(X, input_name=\u001B[33m\"X\"\u001B[39m, **check_params)\n\u001B[32m   2955\u001B[39m     \u001B[38;5;28;01melif\u001B[39;00m no_val_X \u001B[38;5;28;01mand\u001B[39;00m \u001B[38;5;28;01mnot\u001B[39;00m no_val_y:\n\u001B[32m   2956\u001B[39m         out = _check_y(y, **check_params)\n\u001B[32m   2957\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py\u001B[39m in \u001B[36m?\u001B[39m\u001B[34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001B[39m\n\u001B[32m   1050\u001B[39m                         )\n\u001B[32m   1051\u001B[39m                     array = xp.astype(array, dtype, copy=\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[32m   1052\u001B[39m                 \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m   1053\u001B[39m                     array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n\u001B[32m-> \u001B[39m\u001B[32m1054\u001B[39m             \u001B[38;5;28;01mexcept\u001B[39;00m ComplexWarning \u001B[38;5;28;01mas\u001B[39;00m complex_warning:\n\u001B[32m   1055\u001B[39m                 raise ValueError(\n\u001B[32m   1056\u001B[39m                     \u001B[33m\"Complex data not supported\\n{}\\n\"\u001B[39m.format(array)\n\u001B[32m   1057\u001B[39m                 ) \u001B[38;5;28;01mfrom\u001B[39;00m complex_warning\n",
      "\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\u001B[39m in \u001B[36m?\u001B[39m\u001B[34m(array, dtype, order, copy, xp, device)\u001B[39m\n\u001B[32m    753\u001B[39m         \u001B[38;5;66;03m# Use NumPy API to support order\u001B[39;00m\n\u001B[32m    754\u001B[39m         \u001B[38;5;28;01mif\u001B[39;00m copy \u001B[38;5;28;01mis\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[32m    755\u001B[39m             array = numpy.array(array, order=order, dtype=dtype)\n\u001B[32m    756\u001B[39m         \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m757\u001B[39m             array = numpy.asarray(array, order=order, dtype=dtype)\n\u001B[32m    758\u001B[39m \n\u001B[32m    759\u001B[39m         \u001B[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001B[39;00m\n\u001B[32m    760\u001B[39m         \u001B[38;5;66;03m# container that is consistent with the input's namespace.\u001B[39;00m\n",
      "\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\generic.py\u001B[39m in \u001B[36m?\u001B[39m\u001B[34m(self, dtype, copy)\u001B[39m\n\u001B[32m   2149\u001B[39m     def __array__(\n\u001B[32m   2150\u001B[39m         self, dtype: npt.DTypeLike | \u001B[38;5;28;01mNone\u001B[39;00m = \u001B[38;5;28;01mNone\u001B[39;00m, copy: bool_t | \u001B[38;5;28;01mNone\u001B[39;00m = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   2151\u001B[39m     ) -> np.ndarray:\n\u001B[32m   2152\u001B[39m         values = self._values\n\u001B[32m-> \u001B[39m\u001B[32m2153\u001B[39m         arr = np.asarray(values, dtype=dtype)\n\u001B[32m   2154\u001B[39m         if (\n\u001B[32m   2155\u001B[39m             astype_is_view(values.dtype, arr.dtype)\n\u001B[32m   2156\u001B[39m             \u001B[38;5;28;01mand\u001B[39;00m using_copy_on_write()\n",
      "\u001B[31mValueError\u001B[39m: could not convert string to float: 'a'"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.3, random_state=42)\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)"
   ],
   "id": "3033dad920b3054a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
